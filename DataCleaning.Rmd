---
title: "Cleaning Data"
author: "Rizky Susanto - Henricus Primastavia"
date: "2022-11-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tm) # membersihkan data
library(vroom) # membaca Dataset
library(here) # menyimpan Dataset
```

```{r load dataset}
dReview <- vroom(here('Halodoc.csv'))

review <- dReview$content
review1 <- Corpus(VectorSource(review))
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
reviewclean <- tm_map(review1, removeURL)
removeNL <- function(y) gsub("\n", " ", y)
reviewclean <- tm_map(review1, removeNL)
replacecomma <- function(y) gsub(",", "", y)
reviewclean <- tm_map(reviewclean, replacecomma)
removetitik2 <- function(y) gsub(":", "", y)
reviewclean <- tm_map(reviewclean, removetitik2)
removetitikkoma <- function(y) gsub(";", " ", y)
reviewclean <- tm_map(reviewclean, removetitikkoma)
removetitik3 <- function(y) gsub("p...", "", y)
reviewclean <- tm_map(reviewclean, removetitik3)
removeamp <- function(y) gsub("&amp", "", y)
reviewclean <- tm_map(reviewclean, removeamp)
removeUN <- function(z) gsub("@\\w+", "", z)
reviewclean <- tm_map(reviewclean, removeUN)
remove.all <- function(xy) gsub("[^[:alpha:][:space:]]*", "", xy)
reviewclean <- tm_map(reviewclean, remove.all)
reviewclean <- tm_map(reviewclean, removePunctuation)
reviewclean <- tm_map(reviewclean, tolower)
MyStopWords <- readLines("stopwords-id.txt")
reviewclean <- tm_map(reviewclean,removeWords,MyStopWords)
dataframe <- data.frame(text=unlist(sapply(reviewclean,`[`)),stringsAsFactors = F)
View(dataframe)

write.csv(dataframe,file = 'HalodocClean.csv')
```